# Ollama Configuration
# The model you are running in Ollama (e.g., "llama3", "codellama", "mistral", "llama3.2", etc.)
OLLAMA_MODEL=llama3

# The address where your Ollama server is running. Default is usually correct.
OLLAMA_HOST=http://localhost:11434
